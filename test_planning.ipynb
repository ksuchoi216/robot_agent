{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc18388b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pprint import pprint\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "from src import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3514c88f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "704d54f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paths=PathsConfig(output_dir='output/', prompt_dir='src/graph/prompts/') runner=RunnerConfig(intent_node=NodeConfig(model_name='gpt41mini', prompt_cache_key='intent_node'), supervisor_node=NodeConfig(model_name='gpt41mini', prompt_cache_key='supervisor_node'), feedback_node=NodeConfig(model_name='gpt41mini', prompt_cache_key='feedback_node'), goal_node=NodeConfig(model_name='gpt41mini', prompt_cache_key='goal_node'), task_node=NodeConfig(model_name='gpt41mini', prompt_cache_key='task_node')) skills=[RobotSkillConfig(name='robot1', skills=['GoToObject', 'OpenObject', 'CloseObject', 'PickObject', 'PlaceObject'])] tasks={'GoToObject': {'description': 'Move to the specified object.', 'template': 'GoToObject <robot><object>'}, 'OpenObject': {'description': 'Open the specified object.', 'template': 'OpenObject <robot><object>'}, 'CloseObject': {'description': 'Close the specified object.', 'template': 'CloseObject <robot><object>'}, 'PickObject': {'description': 'Pick up the specified object.', 'template': 'PickObject <robot><object>'}, 'PlaceObject': {'description': 'Place the specified object at the designated location.', 'template': 'PlaceObject <robot><object><receptacleObject>'}}\n"
     ]
    }
   ],
   "source": [
    "# use the already-imported src.utils (imported in an earlier cell)\n",
    "from src.config import load_config\n",
    "\n",
    "config = load_config()\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04582a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making inputs for state...\n",
      "Group: counter_1_left_left_group\n",
      "Group: island_left_group\n",
      "url: http://127.0.0.1:8800\n",
      "Groups found: dict_keys(['counter_corner_main_main_group', 'counter_main_main_group', 'stovetop_main_group', 'counter_1_right_main_group', 'fridge_main_group', 'fridge_housing_main_group', 'stack_1_main_group', 'stack_2_main_group', 'stack_3_main_group', 'hood_main_group', 'cab_main_main_group', 'shelves_main_group', 'fridge_cab_main_group', 'cab_1_left_group', 'window_group', 'cab_2_left_group', 'cab_corner_3_left_group', 'cab_corner_4_left_group', 'sink_left_group', 'counter_1_left_left_group', 'counter_corner_left_group', 'island_left_group', 'microwave_left_group', 'stack_1_left_group', 'stack_2_left_group', 'stack_3_left_group'])\n",
      "{'feedback_result': {},\n",
      " 'inputs': {'group_list_text': '[\\n'\n",
      "                               '    \"counter_corner_main_main_group\",\\n'\n",
      "                               '    \"counter_main_main_group\",\\n'\n",
      "                               '    \"stovetop_main_group\",\\n'\n",
      "                               '    \"counter_1_right_main_group\",\\n'\n",
      "                               '    \"fridge_main_group\",\\n'\n",
      "                               '    \"fridge_housing_main_group\",\\n'\n",
      "                               '    \"stack_1_main_group\",\\n'\n",
      "                               '    \"stack_2_main_group\",\\n'\n",
      "                               '    \"stack_3_main_group\",\\n'\n",
      "                               '    \"hood_main_group\",\\n'\n",
      "                               '    \"cab_main_main_group\",\\n'\n",
      "                               '    \"shelves_main_group\",\\n'\n",
      "                               '    \"fridge_cab_main_group\",\\n'\n",
      "                               '    \"cab_1_left_group\",\\n'\n",
      "                               '    \"window_group\",\\n'\n",
      "                               '    \"cab_2_left_group\",\\n'\n",
      "                               '    \"cab_corner_3_left_group\",\\n'\n",
      "                               '    \"cab_corner_4_left_group\",\\n'\n",
      "                               '    \"sink_left_group\",\\n'\n",
      "                               '    \"counter_1_left_left_group\",\\n'\n",
      "                               '    \"counter_corner_left_group\",\\n'\n",
      "                               '    \"island_left_group\",\\n'\n",
      "                               '    \"microwave_left_group\",\\n'\n",
      "                               '    \"stack_1_left_group\",\\n'\n",
      "                               '    \"stack_2_left_group\",\\n'\n",
      "                               '    \"stack_3_left_group\",\\n'\n",
      "                               ']',\n",
      "            'object_text': '{{{{\\n'\n",
      "                           '\"object_name\": \"object_bowl_0\", \"object_in_group\": '\n",
      "                           '\"counter_1_left_left_group\"\\n'\n",
      "                           '\"object_name\": \"object_fork_0\", \"object_in_group\": '\n",
      "                           '\"island_left_group\"\\n'\n",
      "                           '}}}}',\n",
      "            'skill_text': 'from robot1.skills import GoToObject, OpenObject, '\n",
      "                          'CloseObject, PickObject, PlaceObject'},\n",
      " 'intent_result': {},\n",
      " 'subgoals': [],\n",
      " 'supervisor_result': {},\n",
      " 'tasks': [],\n",
      " 'user_queries': ['put a fork on the island table']}\n"
     ]
    }
   ],
   "source": [
    "from src.runner.state import StateMaker\n",
    "\n",
    "\n",
    "state_maker = StateMaker(config)\n",
    "state = state_maker.make(user_query=\"put a fork on the island table\")\n",
    "\n",
    "pprint(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "34dc5486",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-05 13:40:49,874 [INFO] src.runner.graph: ============= USER_INPUT_NODE ==============\n",
      "2025-12-05 13:40:51,117 [INFO] src.runner.graph: User Query: place a apple on island.\n",
      "\n",
      "2025-12-05 13:40:51,121 [INFO] src.runner.graph: ============= INTENT_NODE ==============\n",
      "2025-12-05 13:40:52,863 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-05 13:40:52,877 [INFO] src.runner.graph: AI Answer:\n",
      "{'intent': 'new'}\n",
      "\n",
      "2025-12-05 13:40:52,882 [INFO] src.runner.graph: ============= SUPERVISOR_NODE ==============\n",
      "2025-12-05 13:40:54,905 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-05 13:40:54,911 [INFO] src.runner.graph: AI Answer:\n",
      "{'is_feasible': False, 'reasons': ['사과 객체가 존재하지 않음', '사과가 위치한 그룹이 없음'], 'user_final_query': '사과를 아일랜드 식탁에 놓아줘.'}\n",
      "\n",
      "2025-12-05 13:40:54,914 [INFO] src.runner.graph: ============= FEEDBACK_NODE ==============\n",
      "2025-12-05 13:40:57,029 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-05 13:40:57,036 [INFO] src.runner.graph: AI Answer:\n",
      "{'suggestion': '그릇을 아일랜드 식탁에 놓아줘.', 'reason': ['사과 객체가 없습니다.', '사과를 놓을 아일랜드 식탁 위치가 명확하지 않습니다.']}\n",
      "\n",
      "2025-12-05 13:40:57,039 [INFO] src.runner.graph: ============= USER_INPUT_NODE ==============\n",
      "2025-12-05 13:41:03,044 [INFO] src.runner.graph: User Query: 좋아\n",
      "\n",
      "2025-12-05 13:41:03,098 [INFO] src.runner.graph: ============= INTENT_NODE ==============\n",
      "2025-12-05 13:41:04,684 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-05 13:41:04,695 [INFO] src.runner.graph: AI Answer:\n",
      "{'intent': 'accept'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from src.runner.runner import SupervisedPlanRunner\n",
    "\n",
    "runner = SupervisedPlanRunner(config=config)\n",
    "\n",
    "# Add a small delay if you're making multiple rapid requests\n",
    "# time.sleep(1)\n",
    "\n",
    "final_state = runner.invoke(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3da14511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<langgraph.graph.state.CompiledStateGraph object at 0x16a6970d0>\n"
     ]
    }
   ],
   "source": [
    "graph = runner.graph\n",
    "print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cdd42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 21:19:04,695 [INFO] src.runner.graph: ============= GOAL_NODE ==============\n",
      "2025-12-04 21:19:06,099 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-04 21:19:06,102 [INFO] src.runner.graph: AI Answer:\n",
      "{'subgoals': ['Put a fork on the island table']}\n",
      "\n",
      "2025-12-04 21:19:06,103 [INFO] src.runner.graph: ============= TASK_NODE ==============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgoals Text:\n",
      "1. Put a fork on the island table\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 21:19:09,184 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-04 21:19:09,193 [INFO] src.runner.graph: AI Answer:\n",
      "{'tasks': [{'subgoal': 'Put a fork on the island table', 'tasks': [{'skill': 'GoToObject', 'target': 'object_fork_0'}, {'skill': 'PickObject', 'target': 'object_fork_0'}, {'skill': 'GoToObject', 'target': 'island_left_group'}, {'skill': 'PlaceObject', 'target': 'island_left_group'}]}]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import time\n",
    "# from src.runner.runner import PlanRunner\n",
    "\n",
    "# runner = PlanRunner(config=config)\n",
    "\n",
    "# # Add a small delay if you're making multiple rapid requests\n",
    "# # time.sleep(1)\n",
    "\n",
    "# final_state = runner.invoke(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "02ad05cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_image = graph.get_graph().draw_mermaid_png()\n",
    "with open(\"graph.png\", \"wb\") as f:\n",
    "    f.write(graph_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5998b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079a7677",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
